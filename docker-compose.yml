services:
    zookeeper:
        platform: linux/amd64
        image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION:-7.7.0}
        container_name: zookeeper
        restart: unless-stopped
        ports:
            - '32181:32181'
            - '2888:2888'
            - '3888:3888'
        environment:
            ZOOKEEPER_SERVER_ID: 1
            ZOOKEEPER_CLIENT_PORT: 32181
            ZOOKEEPER_TICK_TIME: 2000
            ZOOKEEPER_INIT_LIMIT: 5
            ZOOKEEPER_SYNC_LIMIT: 2
            ZOOKEEPER_SERVERS: zookeeper:2888:3888
        volumes:
            - zookeeper_data:/var/lib/zookeeper/data
            - zookeeper_log:/var/lib/zookeeper/log
        healthcheck:
            test: echo stat | nc localhost 32181
            interval: 10s
            timeout: 10s
            retries: 3
        networks:
            - kafka
        logging:
            driver: "json-file"
            options:
                max-size: "255m"

    broker-1:
        platform: linux/amd64
        image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.7.0}
        hostname: broker-1
        container_name: broker-1
        restart: unless-stopped
        ports:
            - '19092:19092'
            - '9092:9092'
            - '9992:9992'
            - '29092:29092'
            - '39092:39092'
        depends_on:
            - zookeeper
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-1:29092,EXTERNAL://localhost:9092
            #KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-1:29092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
            KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
            KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
            KAFKA_DEFAULT_REPLICATION_FACTOR: 3
            KAFKA_NUM_PARTITIONS: 3
            KAFKA_JMX_PORT: 19102
            KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
        volumes:
            - broker_1_data:/var/lib/kafka/data
        healthcheck:
            test: nc -vz localhost 9092
            interval: 10s
            timeout: 10s
            retries: 3
        networks:
            - kafka
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    broker-2:
        platform: linux/amd64
        image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.7.0}
        container_name: broker-2
        restart: unless-stopped
        ports:
            - '9093:9093'
            - '19093:19093'
            - '29093:29093'
            - '9993:9993'
            - '39093:39093'
        depends_on:
            - zookeeper
        environment:
            KAFKA_BROKER_ID: 2
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-2:29093,EXTERNAL://localhost:9093
            #KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-2:29093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
            KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
            KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
            KAFKA_DEFAULT_REPLICATION_FACTOR: 3
            KAFKA_NUM_PARTITIONS: 3
            KAFKA_JMX_PORT: 19103
            KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
        volumes:
            - broker_2_data:/var/lib/kafka/data
        healthcheck:
            test: nc -vz localhost 9093
            interval: 10s
            timeout: 10s
            retries: 3
        networks:
            - kafka
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    broker-3:
        platform: linux/amd64
        image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.7.0}
        container_name: broker-3
        restart: unless-stopped
        ports:
            - '9094:9094'
            - '19094:19094'
            - '39094:39094'
            - '29094:29094'
            - '9994:9994'
        depends_on:
            - zookeeper
        environment:
            KAFKA_BROKER_ID: 3
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-3:29094,EXTERNAL://localhost:9094
            # KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-3:29094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
            KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
            KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
            KAFKA_DEFAULT_REPLICATION_FACTOR: 3
            KAFKA_NUM_PARTITIONS: 3
            KAFKA_JMX_PORT: 19104
            KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
        volumes:
            - broker_3_data:/var/lib/kafka/data
        healthcheck:
            test: nc -vz localhost 9094
            interval: 10s
            timeout: 10s
            retries: 3
        networks:
            - kafka
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    kafka-ui:
        container_name: kafka-ui
        image: provectuslabs/kafka-ui:latest
        ports:
            - 8087:8080
        depends_on:
            - broker-1
            - broker-2
            - broker-3
        environment:
            KAFKA_CLUSTERS_0_NAME: broker-1
            KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker-1:29092
            KAFKA_CLUSTERS_0_METRICS_PORT: 19101
            KAFKA_CLUSTERS_1_NAME: broker-2
            KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS: broker-2:29093
            KAFKA_CLUSTERS_1_METRICS_PORT: 19102
            KAFKA_CLUSTERS_2_NAME: broker-3
            KAFKA_CLUSTERS_2_BOOTSTRAPSERVERS: broker-3:29094
            KAFKA_CLUSTERS_2_METRICS_PORT: 19103
            DYNAMIC_CONFIG_ENABLED: 'true'
        networks:
            - kafka
        logging:
            driver: "json-file"
            options:
                max-size: "1m"
    database:
        container_name: database_leplus
        image: postgres:${POSTGRES_VERSION:-14}-alpine
        env_file:
            - .env
        environment:
            POSTGRES_DB: ${POSTGRES_DBNAME:-vehicle_leplus}
            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-Admin123}
            POSTGRES_USER: ${POSTGRES_USER:-admin}
        ports:
            - "${POSTGRES_PORT}:5432"
        volumes:
            - leplus-db-data:/var/lib/postgresql/data:rw
        networks:
            - kafka

    pgadmin:
        image: dpage/pgadmin4
        container_name: pgadmin_pfe
        environment:
            - PGADMIN_DEFAULT_EMAIL=admin@admin.com
            - PGADMIN_DEFAULT_PASSWORD=root
        ports:
            - "8081:80"
        networks:
            - kafka

volumes:
    zookeeper_data:
    zookeeper_log:
    broker_1_data:
    broker_2_data:
    broker_3_data:
    leplus-db-data:

networks:
    kafka:
        name: kafka
